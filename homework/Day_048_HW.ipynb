{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "# https://www.kaggle.com/chahat1/data-science-london-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/d48/train.csv', header = None)\n",
    "train_labels = pd.read_csv('./data/d48/trainLabels.csv',header = None)\n",
    "test_data = pd.read_csv('./data/d48/test.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (1000, 40)\n",
      "test shape: (9000, 40)\n",
      "trainLabel shape: (1000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299403</td>\n",
       "      <td>-1.226624</td>\n",
       "      <td>1.498425</td>\n",
       "      <td>-1.176150</td>\n",
       "      <td>5.289853</td>\n",
       "      <td>0.208297</td>\n",
       "      <td>2.404498</td>\n",
       "      <td>1.594506</td>\n",
       "      <td>-0.051608</td>\n",
       "      <td>0.663234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.850465</td>\n",
       "      <td>-0.622990</td>\n",
       "      <td>-1.833057</td>\n",
       "      <td>0.293024</td>\n",
       "      <td>3.552681</td>\n",
       "      <td>0.717611</td>\n",
       "      <td>3.305972</td>\n",
       "      <td>-2.715559</td>\n",
       "      <td>-2.682409</td>\n",
       "      <td>0.101050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.174176</td>\n",
       "      <td>0.332157</td>\n",
       "      <td>0.949919</td>\n",
       "      <td>-1.285328</td>\n",
       "      <td>2.199061</td>\n",
       "      <td>-0.151268</td>\n",
       "      <td>-0.427039</td>\n",
       "      <td>2.619246</td>\n",
       "      <td>-0.765884</td>\n",
       "      <td>-0.093780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.819750</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>2.038836</td>\n",
       "      <td>0.468579</td>\n",
       "      <td>-0.517657</td>\n",
       "      <td>0.422326</td>\n",
       "      <td>0.803699</td>\n",
       "      <td>1.213219</td>\n",
       "      <td>1.382932</td>\n",
       "      <td>-1.817761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.192222</td>\n",
       "      <td>-0.414371</td>\n",
       "      <td>0.067054</td>\n",
       "      <td>-2.233568</td>\n",
       "      <td>3.658881</td>\n",
       "      <td>0.089007</td>\n",
       "      <td>0.203439</td>\n",
       "      <td>-4.219054</td>\n",
       "      <td>-1.184919</td>\n",
       "      <td>-1.240310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604501</td>\n",
       "      <td>0.750054</td>\n",
       "      <td>-3.360521</td>\n",
       "      <td>0.856988</td>\n",
       "      <td>-2.751451</td>\n",
       "      <td>-1.582735</td>\n",
       "      <td>1.672246</td>\n",
       "      <td>0.656438</td>\n",
       "      <td>-0.932473</td>\n",
       "      <td>2.987436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.573270</td>\n",
       "      <td>-0.580318</td>\n",
       "      <td>-0.866332</td>\n",
       "      <td>-0.603812</td>\n",
       "      <td>3.125716</td>\n",
       "      <td>0.870321</td>\n",
       "      <td>-0.161992</td>\n",
       "      <td>4.499666</td>\n",
       "      <td>1.038741</td>\n",
       "      <td>-1.092716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>1.275598</td>\n",
       "      <td>-3.480110</td>\n",
       "      <td>-1.065252</td>\n",
       "      <td>2.153133</td>\n",
       "      <td>1.563539</td>\n",
       "      <td>2.767117</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.619645</td>\n",
       "      <td>1.883397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.613071</td>\n",
       "      <td>-0.644204</td>\n",
       "      <td>1.112558</td>\n",
       "      <td>-0.032397</td>\n",
       "      <td>3.490142</td>\n",
       "      <td>-0.011935</td>\n",
       "      <td>1.443521</td>\n",
       "      <td>-4.290282</td>\n",
       "      <td>-1.761308</td>\n",
       "      <td>0.807652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513906</td>\n",
       "      <td>-1.803473</td>\n",
       "      <td>0.518579</td>\n",
       "      <td>-0.205029</td>\n",
       "      <td>-4.744566</td>\n",
       "      <td>-1.520015</td>\n",
       "      <td>1.830651</td>\n",
       "      <td>0.870772</td>\n",
       "      <td>-1.894609</td>\n",
       "      <td>0.408332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.299403 -1.226624  1.498425 -1.176150  5.289853  0.208297  2.404498   \n",
       "1 -1.174176  0.332157  0.949919 -1.285328  2.199061 -0.151268 -0.427039   \n",
       "2  1.192222 -0.414371  0.067054 -2.233568  3.658881  0.089007  0.203439   \n",
       "3  1.573270 -0.580318 -0.866332 -0.603812  3.125716  0.870321 -0.161992   \n",
       "4 -0.613071 -0.644204  1.112558 -0.032397  3.490142 -0.011935  1.443521   \n",
       "\n",
       "         7         8         9   ...        30        31        32        33  \\\n",
       "0  1.594506 -0.051608  0.663234  ... -0.850465 -0.622990 -1.833057  0.293024   \n",
       "1  2.619246 -0.765884 -0.093780  ... -0.819750  0.012037  2.038836  0.468579   \n",
       "2 -4.219054 -1.184919 -1.240310  ... -0.604501  0.750054 -3.360521  0.856988   \n",
       "3  4.499666  1.038741 -1.092716  ...  1.022959  1.275598 -3.480110 -1.065252   \n",
       "4 -4.290282 -1.761308  0.807652  ...  0.513906 -1.803473  0.518579 -0.205029   \n",
       "\n",
       "         34        35        36        37        38        39  \n",
       "0  3.552681  0.717611  3.305972 -2.715559 -2.682409  0.101050  \n",
       "1 -0.517657  0.422326  0.803699  1.213219  1.382932 -1.817761  \n",
       "2 -2.751451 -1.582735  1.672246  0.656438 -0.932473  2.987436  \n",
       "3  2.153133  1.563539  2.767117  0.215748  0.619645  1.883397  \n",
       "4 -4.744566 -1.520015  1.830651  0.870772 -1.894609  0.408332  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('train shape:', train_data.shape)\n",
    "print('test shape:', test_data.shape)\n",
    "print('trainLabel shape:', train_labels.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 40 columns):\n",
      "0     1000 non-null float64\n",
      "1     1000 non-null float64\n",
      "2     1000 non-null float64\n",
      "3     1000 non-null float64\n",
      "4     1000 non-null float64\n",
      "5     1000 non-null float64\n",
      "6     1000 non-null float64\n",
      "7     1000 non-null float64\n",
      "8     1000 non-null float64\n",
      "9     1000 non-null float64\n",
      "10    1000 non-null float64\n",
      "11    1000 non-null float64\n",
      "12    1000 non-null float64\n",
      "13    1000 non-null float64\n",
      "14    1000 non-null float64\n",
      "15    1000 non-null float64\n",
      "16    1000 non-null float64\n",
      "17    1000 non-null float64\n",
      "18    1000 non-null float64\n",
      "19    1000 non-null float64\n",
      "20    1000 non-null float64\n",
      "21    1000 non-null float64\n",
      "22    1000 non-null float64\n",
      "23    1000 non-null float64\n",
      "24    1000 non-null float64\n",
      "25    1000 non-null float64\n",
      "26    1000 non-null float64\n",
      "27    1000 non-null float64\n",
      "28    1000 non-null float64\n",
      "29    1000 non-null float64\n",
      "30    1000 non-null float64\n",
      "31    1000 non-null float64\n",
      "32    1000 non-null float64\n",
      "33    1000 non-null float64\n",
      "34    1000 non-null float64\n",
      "35    1000 non-null float64\n",
      "36    1000 non-null float64\n",
      "37    1000 non-null float64\n",
      "38    1000 non-null float64\n",
      "39    1000 non-null float64\n",
      "dtypes: float64(40)\n",
      "memory usage: 312.6 KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.025596</td>\n",
       "      <td>-0.024526</td>\n",
       "      <td>-0.024088</td>\n",
       "      <td>-0.002271</td>\n",
       "      <td>1.092329</td>\n",
       "      <td>-0.006250</td>\n",
       "      <td>0.497342</td>\n",
       "      <td>-0.037883</td>\n",
       "      <td>0.026391</td>\n",
       "      <td>-0.003597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030651</td>\n",
       "      <td>0.022951</td>\n",
       "      <td>-0.542491</td>\n",
       "      <td>-0.011608</td>\n",
       "      <td>-0.483507</td>\n",
       "      <td>0.033371</td>\n",
       "      <td>0.567185</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>-0.892659</td>\n",
       "      <td>0.609451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.008282</td>\n",
       "      <td>1.016298</td>\n",
       "      <td>0.979109</td>\n",
       "      <td>0.970575</td>\n",
       "      <td>4.538834</td>\n",
       "      <td>0.989128</td>\n",
       "      <td>2.118819</td>\n",
       "      <td>2.232256</td>\n",
       "      <td>1.001064</td>\n",
       "      <td>1.013520</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011645</td>\n",
       "      <td>1.001375</td>\n",
       "      <td>2.239939</td>\n",
       "      <td>1.022456</td>\n",
       "      <td>2.121281</td>\n",
       "      <td>1.007044</td>\n",
       "      <td>2.227876</td>\n",
       "      <td>0.997635</td>\n",
       "      <td>2.022022</td>\n",
       "      <td>2.045439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.365711</td>\n",
       "      <td>-3.492086</td>\n",
       "      <td>-2.695602</td>\n",
       "      <td>-3.460471</td>\n",
       "      <td>-16.421901</td>\n",
       "      <td>-3.041250</td>\n",
       "      <td>-7.224761</td>\n",
       "      <td>-6.509084</td>\n",
       "      <td>-3.145588</td>\n",
       "      <td>-2.749812</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.379194</td>\n",
       "      <td>-2.971125</td>\n",
       "      <td>-7.840890</td>\n",
       "      <td>-2.999564</td>\n",
       "      <td>-7.124105</td>\n",
       "      <td>-2.952358</td>\n",
       "      <td>-5.452254</td>\n",
       "      <td>-3.473913</td>\n",
       "      <td>-8.051722</td>\n",
       "      <td>-7.799086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.669010</td>\n",
       "      <td>-0.693937</td>\n",
       "      <td>-0.698830</td>\n",
       "      <td>-0.617557</td>\n",
       "      <td>-1.801997</td>\n",
       "      <td>-0.732265</td>\n",
       "      <td>-0.838619</td>\n",
       "      <td>-1.604037</td>\n",
       "      <td>-0.677562</td>\n",
       "      <td>-0.682220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.659457</td>\n",
       "      <td>-0.696032</td>\n",
       "      <td>-2.121943</td>\n",
       "      <td>-0.664550</td>\n",
       "      <td>-1.879247</td>\n",
       "      <td>-0.642861</td>\n",
       "      <td>-1.059786</td>\n",
       "      <td>-0.691162</td>\n",
       "      <td>-2.220126</td>\n",
       "      <td>-0.565041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.027895</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.862818</td>\n",
       "      <td>0.027041</td>\n",
       "      <td>0.582321</td>\n",
       "      <td>0.018809</td>\n",
       "      <td>0.022092</td>\n",
       "      <td>-0.036110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049416</td>\n",
       "      <td>0.049778</td>\n",
       "      <td>-0.568262</td>\n",
       "      <td>-0.028097</td>\n",
       "      <td>-0.493575</td>\n",
       "      <td>0.037732</td>\n",
       "      <td>0.455474</td>\n",
       "      <td>0.038284</td>\n",
       "      <td>-0.855470</td>\n",
       "      <td>0.779944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.762520</td>\n",
       "      <td>0.682753</td>\n",
       "      <td>0.661434</td>\n",
       "      <td>0.640743</td>\n",
       "      <td>3.843172</td>\n",
       "      <td>0.671456</td>\n",
       "      <td>1.913664</td>\n",
       "      <td>1.438304</td>\n",
       "      <td>0.741310</td>\n",
       "      <td>0.665364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747031</td>\n",
       "      <td>0.699917</td>\n",
       "      <td>0.939348</td>\n",
       "      <td>0.651374</td>\n",
       "      <td>1.005795</td>\n",
       "      <td>0.691800</td>\n",
       "      <td>2.122157</td>\n",
       "      <td>0.693535</td>\n",
       "      <td>0.388698</td>\n",
       "      <td>1.992193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.326246</td>\n",
       "      <td>3.583870</td>\n",
       "      <td>2.546507</td>\n",
       "      <td>3.088738</td>\n",
       "      <td>17.565345</td>\n",
       "      <td>3.102997</td>\n",
       "      <td>7.592666</td>\n",
       "      <td>7.130097</td>\n",
       "      <td>3.145258</td>\n",
       "      <td>3.919426</td>\n",
       "      <td>...</td>\n",
       "      <td>2.844792</td>\n",
       "      <td>3.688047</td>\n",
       "      <td>7.160379</td>\n",
       "      <td>3.353631</td>\n",
       "      <td>6.005818</td>\n",
       "      <td>3.420561</td>\n",
       "      <td>6.603499</td>\n",
       "      <td>3.492548</td>\n",
       "      <td>5.774120</td>\n",
       "      <td>6.803984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0            1            2            3            4   \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.025596    -0.024526    -0.024088    -0.002271     1.092329   \n",
       "std       1.008282     1.016298     0.979109     0.970575     4.538834   \n",
       "min      -3.365711    -3.492086    -2.695602    -3.460471   -16.421901   \n",
       "25%      -0.669010    -0.693937    -0.698830    -0.617557    -1.801997   \n",
       "50%       0.027895    -0.033194     0.008145     0.002327     0.862818   \n",
       "75%       0.762520     0.682753     0.661434     0.640743     3.843172   \n",
       "max       3.326246     3.583870     2.546507     3.088738    17.565345   \n",
       "\n",
       "                5            6            7            8            9   ...  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  ...   \n",
       "mean     -0.006250     0.497342    -0.037883     0.026391    -0.003597  ...   \n",
       "std       0.989128     2.118819     2.232256     1.001064     1.013520  ...   \n",
       "min      -3.041250    -7.224761    -6.509084    -3.145588    -2.749812  ...   \n",
       "25%      -0.732265    -0.838619    -1.604037    -0.677562    -0.682220  ...   \n",
       "50%       0.027041     0.582321     0.018809     0.022092    -0.036110  ...   \n",
       "75%       0.671456     1.913664     1.438304     0.741310     0.665364  ...   \n",
       "max       3.102997     7.592666     7.130097     3.145258     3.919426  ...   \n",
       "\n",
       "                30           31           32           33           34  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.030651     0.022951    -0.542491    -0.011608    -0.483507   \n",
       "std       1.011645     1.001375     2.239939     1.022456     2.121281   \n",
       "min      -3.379194    -2.971125    -7.840890    -2.999564    -7.124105   \n",
       "25%      -0.659457    -0.696032    -2.121943    -0.664550    -1.879247   \n",
       "50%       0.049416     0.049778    -0.568262    -0.028097    -0.493575   \n",
       "75%       0.747031     0.699917     0.939348     0.651374     1.005795   \n",
       "max       2.844792     3.688047     7.160379     3.353631     6.005818   \n",
       "\n",
       "                35           36           37           38           39  \n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
       "mean      0.033371     0.567185     0.006849    -0.892659     0.609451  \n",
       "std       1.007044     2.227876     0.997635     2.022022     2.045439  \n",
       "min      -2.952358    -5.452254    -3.473913    -8.051722    -7.799086  \n",
       "25%      -0.642861    -1.059786    -0.691162    -2.220126    -0.565041  \n",
       "50%       0.037732     0.455474     0.038284    -0.855470     0.779944  \n",
       "75%       0.691800     2.122157     0.693535     0.388698     1.992193  \n",
       "max       3.420561     6.603499     3.492548     5.774120     6.803984  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 40), (300, 40), (700, 1), (300, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data, train_labels, test_size = 0.30, random_state = 100) ## 101 ?\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes:  0.8433333333333334\n",
      "KNN:  0.8733333333333333\n",
      "Random Forest:  0.8566666666666667\n",
      "Logistic Regression:  0.81\n",
      "SVM:  0.89\n",
      "Decision Tree:  0.7566666666666667\n",
      "XGBoost:  0.8766666666666667\n"
     ]
    }
   ],
   "source": [
    "## Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(x_train, y_train.values.ravel())\n",
    "naive_predicted = model.predict(x_test)\n",
    "print('Naive Bayes: ', accuracy_score(y_test, naive_predicted))\n",
    "\n",
    "## KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(x_train, y_train.values.ravel())\n",
    "knn_predicted = knn_model.predict(x_test)\n",
    "print('KNN: ', accuracy_score(y_test,knn_predicted))\n",
    "\n",
    "## Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_model = RandomForestClassifier(n_estimators = 100, random_state = 99)\n",
    "rfc_model.fit(x_train,y_train.values.ravel())\n",
    "rfc_predicted = rfc_model.predict(x_test)\n",
    "print('Random Forest: ', accuracy_score(y_test, rfc_predicted))\n",
    "\n",
    "## Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(solver = 'saga')\n",
    "lr_model.fit(x_train, y_train.values.ravel())\n",
    "lr_predicted = lr_model.predict(x_test)\n",
    "print('Logistic Regression: ', accuracy_score(y_test, lr_predicted))\n",
    "\n",
    "## SVM \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(gamma = 'auto')\n",
    "svc_model.fit(x_train, y_train.values.ravel())\n",
    "svc_predicted = svc_model.predict(x_test)\n",
    "print('SVM: ', accuracy_score(y_test, svc_predicted))\n",
    "\n",
    "## Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree_model = DecisionTreeClassifier()\n",
    "dtree_model.fit(x_train, y_train.values.ravel())\n",
    "dtree_predicted = dtree_model.predict(x_test)\n",
    "print('Decision Tree: ', accuracy_score(y_test, dtree_predicted))\n",
    "\n",
    "## XGBOOST\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train, y_train.values.ravel())\n",
    "xgb_predicted = xgb.predict(x_test)\n",
    "print('XGBoost: ', accuracy_score(y_test, xgb_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "\n",
    "norm = Normalizer()\n",
    "norm_train_data = norm.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299403</td>\n",
       "      <td>-1.226624</td>\n",
       "      <td>1.498425</td>\n",
       "      <td>-1.176150</td>\n",
       "      <td>5.289853</td>\n",
       "      <td>0.208297</td>\n",
       "      <td>2.404498</td>\n",
       "      <td>1.594506</td>\n",
       "      <td>-0.051608</td>\n",
       "      <td>0.663234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.850465</td>\n",
       "      <td>-0.622990</td>\n",
       "      <td>-1.833057</td>\n",
       "      <td>0.293024</td>\n",
       "      <td>3.552681</td>\n",
       "      <td>0.717611</td>\n",
       "      <td>3.305972</td>\n",
       "      <td>-2.715559</td>\n",
       "      <td>-2.682409</td>\n",
       "      <td>0.101050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.174176</td>\n",
       "      <td>0.332157</td>\n",
       "      <td>0.949919</td>\n",
       "      <td>-1.285328</td>\n",
       "      <td>2.199061</td>\n",
       "      <td>-0.151268</td>\n",
       "      <td>-0.427039</td>\n",
       "      <td>2.619246</td>\n",
       "      <td>-0.765884</td>\n",
       "      <td>-0.093780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.819750</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>2.038836</td>\n",
       "      <td>0.468579</td>\n",
       "      <td>-0.517657</td>\n",
       "      <td>0.422326</td>\n",
       "      <td>0.803699</td>\n",
       "      <td>1.213219</td>\n",
       "      <td>1.382932</td>\n",
       "      <td>-1.817761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.192222</td>\n",
       "      <td>-0.414371</td>\n",
       "      <td>0.067054</td>\n",
       "      <td>-2.233568</td>\n",
       "      <td>3.658881</td>\n",
       "      <td>0.089007</td>\n",
       "      <td>0.203439</td>\n",
       "      <td>-4.219054</td>\n",
       "      <td>-1.184919</td>\n",
       "      <td>-1.240310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604501</td>\n",
       "      <td>0.750054</td>\n",
       "      <td>-3.360521</td>\n",
       "      <td>0.856988</td>\n",
       "      <td>-2.751451</td>\n",
       "      <td>-1.582735</td>\n",
       "      <td>1.672246</td>\n",
       "      <td>0.656438</td>\n",
       "      <td>-0.932473</td>\n",
       "      <td>2.987436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.573270</td>\n",
       "      <td>-0.580318</td>\n",
       "      <td>-0.866332</td>\n",
       "      <td>-0.603812</td>\n",
       "      <td>3.125716</td>\n",
       "      <td>0.870321</td>\n",
       "      <td>-0.161992</td>\n",
       "      <td>4.499666</td>\n",
       "      <td>1.038741</td>\n",
       "      <td>-1.092716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>1.275598</td>\n",
       "      <td>-3.480110</td>\n",
       "      <td>-1.065252</td>\n",
       "      <td>2.153133</td>\n",
       "      <td>1.563539</td>\n",
       "      <td>2.767117</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.619645</td>\n",
       "      <td>1.883397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.613071</td>\n",
       "      <td>-0.644204</td>\n",
       "      <td>1.112558</td>\n",
       "      <td>-0.032397</td>\n",
       "      <td>3.490142</td>\n",
       "      <td>-0.011935</td>\n",
       "      <td>1.443521</td>\n",
       "      <td>-4.290282</td>\n",
       "      <td>-1.761308</td>\n",
       "      <td>0.807652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513906</td>\n",
       "      <td>-1.803473</td>\n",
       "      <td>0.518579</td>\n",
       "      <td>-0.205029</td>\n",
       "      <td>-4.744566</td>\n",
       "      <td>-1.520015</td>\n",
       "      <td>1.830651</td>\n",
       "      <td>0.870772</td>\n",
       "      <td>-1.894609</td>\n",
       "      <td>0.408332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.773247</td>\n",
       "      <td>-0.123227</td>\n",
       "      <td>0.047423</td>\n",
       "      <td>-0.210266</td>\n",
       "      <td>10.377793</td>\n",
       "      <td>0.526604</td>\n",
       "      <td>-2.751616</td>\n",
       "      <td>0.315541</td>\n",
       "      <td>0.608603</td>\n",
       "      <td>-0.043421</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.487714</td>\n",
       "      <td>0.792790</td>\n",
       "      <td>-0.540711</td>\n",
       "      <td>0.114115</td>\n",
       "      <td>-0.277477</td>\n",
       "      <td>-0.896411</td>\n",
       "      <td>-2.805207</td>\n",
       "      <td>0.469162</td>\n",
       "      <td>3.614157</td>\n",
       "      <td>0.081689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.483814</td>\n",
       "      <td>-0.296301</td>\n",
       "      <td>0.452697</td>\n",
       "      <td>0.053363</td>\n",
       "      <td>-4.480227</td>\n",
       "      <td>-1.189786</td>\n",
       "      <td>1.963951</td>\n",
       "      <td>-0.610189</td>\n",
       "      <td>1.312698</td>\n",
       "      <td>2.493390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064301</td>\n",
       "      <td>-1.902989</td>\n",
       "      <td>3.441767</td>\n",
       "      <td>1.481434</td>\n",
       "      <td>-0.507055</td>\n",
       "      <td>-0.117490</td>\n",
       "      <td>1.877093</td>\n",
       "      <td>-0.531129</td>\n",
       "      <td>-1.574326</td>\n",
       "      <td>-1.733600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.763901</td>\n",
       "      <td>-3.492086</td>\n",
       "      <td>0.329564</td>\n",
       "      <td>1.300720</td>\n",
       "      <td>5.037783</td>\n",
       "      <td>0.149122</td>\n",
       "      <td>-5.014214</td>\n",
       "      <td>-1.966723</td>\n",
       "      <td>-1.828132</td>\n",
       "      <td>0.289911</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314328</td>\n",
       "      <td>1.317465</td>\n",
       "      <td>-0.802101</td>\n",
       "      <td>-1.622429</td>\n",
       "      <td>3.930147</td>\n",
       "      <td>0.952521</td>\n",
       "      <td>-0.775724</td>\n",
       "      <td>1.047129</td>\n",
       "      <td>3.252374</td>\n",
       "      <td>-1.320290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.380964</td>\n",
       "      <td>-1.533580</td>\n",
       "      <td>0.786602</td>\n",
       "      <td>1.311827</td>\n",
       "      <td>-6.122086</td>\n",
       "      <td>1.837293</td>\n",
       "      <td>1.872341</td>\n",
       "      <td>-2.604811</td>\n",
       "      <td>-0.179111</td>\n",
       "      <td>2.655691</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.221536</td>\n",
       "      <td>-1.928555</td>\n",
       "      <td>1.500312</td>\n",
       "      <td>0.381377</td>\n",
       "      <td>-1.090007</td>\n",
       "      <td>-0.135532</td>\n",
       "      <td>0.897454</td>\n",
       "      <td>-0.157605</td>\n",
       "      <td>-0.353676</td>\n",
       "      <td>1.203563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.688936</td>\n",
       "      <td>-0.879470</td>\n",
       "      <td>-1.150302</td>\n",
       "      <td>-0.131129</td>\n",
       "      <td>-0.617483</td>\n",
       "      <td>-0.774317</td>\n",
       "      <td>-3.061153</td>\n",
       "      <td>-0.516864</td>\n",
       "      <td>-0.924853</td>\n",
       "      <td>-1.401560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119981</td>\n",
       "      <td>0.531981</td>\n",
       "      <td>-1.326816</td>\n",
       "      <td>-0.457071</td>\n",
       "      <td>-2.998023</td>\n",
       "      <td>-0.061020</td>\n",
       "      <td>2.745646</td>\n",
       "      <td>0.861720</td>\n",
       "      <td>-1.413428</td>\n",
       "      <td>1.714611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3          4         5         6   \\\n",
       "0  0.299403 -1.226624  1.498425 -1.176150   5.289853  0.208297  2.404498   \n",
       "1 -1.174176  0.332157  0.949919 -1.285328   2.199061 -0.151268 -0.427039   \n",
       "2  1.192222 -0.414371  0.067054 -2.233568   3.658881  0.089007  0.203439   \n",
       "3  1.573270 -0.580318 -0.866332 -0.603812   3.125716  0.870321 -0.161992   \n",
       "4 -0.613071 -0.644204  1.112558 -0.032397   3.490142 -0.011935  1.443521   \n",
       "5 -0.773247 -0.123227  0.047423 -0.210266  10.377793  0.526604 -2.751616   \n",
       "6  1.483814 -0.296301  0.452697  0.053363  -4.480227 -1.189786  1.963951   \n",
       "7  0.763901 -3.492086  0.329564  1.300720   5.037783  0.149122 -5.014214   \n",
       "8  0.380964 -1.533580  0.786602  1.311827  -6.122086  1.837293  1.872341   \n",
       "9 -0.688936 -0.879470 -1.150302 -0.131129  -0.617483 -0.774317 -3.061153   \n",
       "\n",
       "         7         8         9   ...        30        31        32        33  \\\n",
       "0  1.594506 -0.051608  0.663234  ... -0.850465 -0.622990 -1.833057  0.293024   \n",
       "1  2.619246 -0.765884 -0.093780  ... -0.819750  0.012037  2.038836  0.468579   \n",
       "2 -4.219054 -1.184919 -1.240310  ... -0.604501  0.750054 -3.360521  0.856988   \n",
       "3  4.499666  1.038741 -1.092716  ...  1.022959  1.275598 -3.480110 -1.065252   \n",
       "4 -4.290282 -1.761308  0.807652  ...  0.513906 -1.803473  0.518579 -0.205029   \n",
       "5  0.315541  0.608603 -0.043421  ... -1.487714  0.792790 -0.540711  0.114115   \n",
       "6 -0.610189  1.312698  2.493390  ... -0.064301 -1.902989  3.441767  1.481434   \n",
       "7 -1.966723 -1.828132  0.289911  ... -0.314328  1.317465 -0.802101 -1.622429   \n",
       "8 -2.604811 -0.179111  2.655691  ... -1.221536 -1.928555  1.500312  0.381377   \n",
       "9 -0.516864 -0.924853 -1.401560  ... -0.119981  0.531981 -1.326816 -0.457071   \n",
       "\n",
       "         34        35        36        37        38        39  \n",
       "0  3.552681  0.717611  3.305972 -2.715559 -2.682409  0.101050  \n",
       "1 -0.517657  0.422326  0.803699  1.213219  1.382932 -1.817761  \n",
       "2 -2.751451 -1.582735  1.672246  0.656438 -0.932473  2.987436  \n",
       "3  2.153133  1.563539  2.767117  0.215748  0.619645  1.883397  \n",
       "4 -4.744566 -1.520015  1.830651  0.870772 -1.894609  0.408332  \n",
       "5 -0.277477 -0.896411 -2.805207  0.469162  3.614157  0.081689  \n",
       "6 -0.507055 -0.117490  1.877093 -0.531129 -1.574326 -1.733600  \n",
       "7  3.930147  0.952521 -0.775724  1.047129  3.252374 -1.320290  \n",
       "8 -1.090007 -0.135532  0.897454 -0.157605 -0.353676  1.203563  \n",
       "9 -2.998023 -0.061020  2.745646  0.861720 -1.413428  1.714611  \n",
       "\n",
       "[10 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.41903120e-02, -9.91054540e-02,  1.21065683e-01,\n",
       "        -9.50274066e-02,  4.27395158e-01,  1.68294252e-02,\n",
       "         1.94272137e-01,  1.28828589e-01, -4.16969639e-03,\n",
       "         5.35862068e-02, -1.13789664e-01,  9.00660326e-02,\n",
       "         7.35572668e-02,  1.79212861e-01,  3.47875642e-01,\n",
       "         7.18463838e-03,  1.36664630e-02,  3.34046208e-02,\n",
       "         1.22312929e-01,  2.15155151e-01, -8.66743956e-02,\n",
       "         1.20474759e-02,  4.52113617e-02,  3.53793244e-01,\n",
       "        -3.74569099e-02, -5.16759834e-03,  4.40278007e-02,\n",
       "         5.75885918e-02, -1.20712210e-01, -2.12990022e-01,\n",
       "        -6.87136003e-02, -5.03346559e-02, -1.48102395e-01,\n",
       "         2.36749895e-02,  2.87039911e-01,  5.79795866e-02,\n",
       "         2.67106956e-01, -2.19404355e-01, -2.16725973e-01,\n",
       "         8.16440197e-03],\n",
       "       [-1.48864595e-01,  4.21116378e-02,  1.20432787e-01,\n",
       "        -1.62956655e-01,  2.78801735e-01, -1.91780934e-02,\n",
       "        -5.41409103e-02,  3.32073782e-01, -9.71004350e-02,\n",
       "        -1.18896627e-02,  1.18585324e-01,  1.34109687e-01,\n",
       "        -6.83704876e-02, -2.18904072e-02, -8.60916404e-02,\n",
       "         7.70026370e-02,  1.45626414e-01,  3.08978021e-01,\n",
       "        -3.96915169e-02,  6.69542152e-02, -6.50995672e-02,\n",
       "         9.71432337e-02, -1.85981783e-01, -2.93993379e-01,\n",
       "         2.08838572e-01, -1.97329239e-01, -2.08630315e-01,\n",
       "        -2.51620334e-02, -1.86631813e-01, -2.41665468e-01,\n",
       "        -1.03929736e-01,  1.52602771e-03,  2.58488064e-01,\n",
       "         5.94074581e-02, -6.56296758e-02,  5.35433788e-02,\n",
       "         1.01894700e-01,  1.53814604e-01,  1.75331112e-01,\n",
       "        -2.30459742e-01],\n",
       "       [ 6.81905522e-02, -2.37004243e-02,  3.83524334e-03,\n",
       "        -1.27751591e-01,  2.09274002e-01,  5.09085852e-03,\n",
       "         1.16359346e-02, -2.41313801e-01, -6.77728491e-02,\n",
       "        -7.09410004e-02, -5.09200177e-02,  5.20467273e-02,\n",
       "        -6.77849795e-01,  1.91745619e-01, -2.78094965e-01,\n",
       "        -5.16663011e-02, -1.04345518e-01,  2.59936374e-03,\n",
       "        -1.21626203e-01,  6.64369413e-02, -5.87926253e-02,\n",
       "        -6.17027886e-02,  1.05728602e-01,  2.14995778e-01,\n",
       "         3.56703253e-02, -5.20739760e-03, -5.90890103e-02,\n",
       "        -1.45364447e-02, -2.50378681e-01, -6.84237070e-02,\n",
       "        -3.45751624e-02,  4.29002364e-02, -1.92208951e-01,\n",
       "         4.90164420e-02, -1.57372502e-01, -9.05263960e-02,\n",
       "         9.56460721e-02,  3.75457194e-02, -5.33338860e-02,\n",
       "         1.70869924e-01],\n",
       "       [ 1.58897748e-01, -5.86111632e-02, -8.74981662e-02,\n",
       "        -6.09840837e-02,  3.15692331e-01,  8.79009963e-02,\n",
       "        -1.63609797e-02,  4.54458976e-01,  1.04911203e-01,\n",
       "        -1.10362543e-01, -7.20597438e-02, -1.37761097e-02,\n",
       "         5.95793421e-03, -1.09427546e-01,  1.63885927e-01,\n",
       "        -1.70241029e-01, -1.23508805e-01, -2.17988713e-02,\n",
       "         1.57165355e-02,  6.34141362e-02, -7.40104679e-02,\n",
       "         1.35129880e-01,  1.34902432e-01,  6.86851640e-02,\n",
       "         5.09793442e-02,  1.21683690e-01,  1.45919780e-02,\n",
       "         6.80721936e-02,  1.03818394e-01,  3.10406655e-01,\n",
       "         1.03317238e-01,  1.28833331e-01, -3.51485546e-01,\n",
       "        -1.07588689e-01,  2.17462991e-01,  1.57914964e-01,\n",
       "         2.79474317e-01,  2.17901512e-02,  6.25831892e-02,\n",
       "         1.90220028e-01],\n",
       "       [-3.31996007e-02, -3.48855280e-02,  6.02482567e-02,\n",
       "        -1.75436691e-03,  1.89001346e-01, -6.46294355e-04,\n",
       "         7.81708865e-02, -2.32331233e-01, -9.53799260e-02,\n",
       "         4.37366975e-02, -2.25587218e-02,  2.34948858e-02,\n",
       "        -6.94393054e-01, -2.61275119e-03, -2.72470178e-01,\n",
       "        -3.81459951e-02,  2.79402793e-02, -1.42741594e-01,\n",
       "        -1.27794402e-01, -2.89177372e-03,  4.01507001e-02,\n",
       "         8.51848395e-02,  3.91897037e-02,  9.39878928e-02,\n",
       "         1.81831238e-02,  3.10244662e-02,  3.38981542e-02,\n",
       "         2.23155297e-02, -2.64473777e-01, -3.02624429e-01,\n",
       "         2.78294782e-02, -9.76633347e-02,  2.80825598e-02,\n",
       "        -1.11029118e-02, -2.56932048e-01, -8.23132381e-02,\n",
       "         9.91350544e-02,  4.71548499e-02, -1.02598614e-01,\n",
       "         2.21123832e-02],\n",
       "       [-5.26094364e-02, -8.38400667e-03,  3.22653768e-03,\n",
       "        -1.43058887e-02,  7.06073972e-01,  3.58285574e-02,\n",
       "        -1.87211733e-01,  2.14684604e-02,  4.14075204e-02,\n",
       "        -2.95425480e-03,  1.30940352e-02, -9.98186048e-03,\n",
       "         2.53962293e-01, -2.13441871e-02,  1.06568418e-01,\n",
       "         3.88092978e-02, -1.66808372e-01,  6.44273733e-02,\n",
       "         2.12159074e-01,  1.15596104e-02, -5.06372782e-02,\n",
       "        -1.16655319e-01,  9.46588654e-02,  2.65177603e-01,\n",
       "         2.46508976e-02,  2.29540439e-03, -8.12655041e-02,\n",
       "        -7.31812845e-02, -8.78830339e-02, -2.68976991e-01,\n",
       "        -1.01219584e-01,  5.39390800e-02, -3.67883757e-02,\n",
       "         7.76404153e-03, -1.88786923e-02, -6.09890998e-02,\n",
       "        -1.90857906e-01,  3.19204117e-02,  2.45896427e-01,\n",
       "         5.55787277e-03],\n",
       "       [ 1.64898973e-01, -3.29284585e-02,  5.03090836e-02,\n",
       "         5.93036032e-03, -4.97895796e-01, -1.32223042e-01,\n",
       "         2.18257453e-01, -6.78113604e-02,  1.45882516e-01,\n",
       "         2.77094938e-01, -2.31570821e-02, -3.10046260e-02,\n",
       "        -1.19284392e-01,  3.01574299e-02, -1.86740158e-01,\n",
       "        -2.14831903e-02, -9.62315566e-02, -8.88795066e-02,\n",
       "         1.16300221e-01,  3.67165737e-02, -2.17447515e-03,\n",
       "         5.23222185e-02, -1.49289494e-01, -8.58682682e-02,\n",
       "        -8.06859222e-02, -2.23317191e-01, -1.81416392e-01,\n",
       "        -8.91222946e-02,  1.63666312e-02, -5.75777500e-02,\n",
       "        -7.14585785e-03, -2.11482613e-01,  3.82489795e-01,\n",
       "         1.64634424e-01, -5.63499473e-02, -1.30568910e-02,\n",
       "         2.08604772e-01, -5.90253633e-02, -1.74957718e-01,\n",
       "        -1.92658122e-01],\n",
       "       [ 4.67889219e-02, -2.13890038e-01,  2.01857670e-02,\n",
       "         7.96690415e-02,  3.08563931e-01,  9.13370316e-03,\n",
       "        -3.07120300e-01, -1.20461676e-01, -1.11972957e-01,\n",
       "         1.77570289e-02, -5.87160814e-02,  3.12099484e-02,\n",
       "         5.39096798e-01, -6.31811541e-02,  6.35109091e-02,\n",
       "         1.62631982e-02, -4.48541241e-02, -2.19694962e-02,\n",
       "         2.11198881e-02, -3.67833719e-02,  1.57568258e-01,\n",
       "         3.88957054e-02, -3.30387637e-02,  4.86313892e-01,\n",
       "         8.02873787e-03,  4.36148195e-02,  1.13384172e-01,\n",
       "        -4.52801258e-02, -4.56135745e-02, -6.84950989e-02,\n",
       "        -1.92525709e-02,  8.06946343e-02, -4.91286500e-02,\n",
       "        -9.93736767e-02,  2.40721245e-01,  5.83418281e-02,\n",
       "        -4.75130722e-02,  6.41365730e-02,  1.99207702e-01,\n",
       "        -8.08677085e-02],\n",
       "       [ 3.69616998e-02, -1.48790164e-01,  7.63173257e-02,\n",
       "         1.27275401e-01, -5.93973829e-01,  1.78256849e-01,\n",
       "         1.81657287e-01, -2.52722643e-01, -1.73776383e-02,\n",
       "         2.57659028e-01,  1.39221463e-01, -7.52805496e-03,\n",
       "         7.32769839e-04,  1.76225641e-01, -1.30894807e-01,\n",
       "        -2.91498791e-02, -6.87429838e-03, -7.43751130e-02,\n",
       "         2.04208030e-01, -3.20413327e-02,  1.73902517e-01,\n",
       "        -7.28326149e-02, -7.63540357e-02, -1.01320207e-01,\n",
       "         7.95021444e-02, -5.13203255e-02,  8.39114915e-02,\n",
       "        -2.26532332e-01,  2.29160670e-01,  1.11712073e-01,\n",
       "        -1.18515240e-01, -1.87111258e-01,  1.45562500e-01,\n",
       "         3.70017502e-02, -1.05754081e-01, -1.31495220e-02,\n",
       "         8.70722699e-02, -1.52911004e-02, -3.43142056e-02,\n",
       "         1.16771492e-01],\n",
       "       [-6.20453811e-02, -7.92047519e-02, -1.03595838e-01,\n",
       "        -1.18094359e-02, -5.56103663e-02, -6.97347670e-02,\n",
       "        -2.75686475e-01, -4.65485949e-02, -8.32919299e-02,\n",
       "        -1.26224088e-01, -7.95555619e-02,  1.26148814e-01,\n",
       "         1.04096237e-01,  1.33851715e-01, -2.69919035e-01,\n",
       "        -6.05171093e-02, -6.93215293e-02, -8.69748177e-02,\n",
       "         3.04992342e-01,  1.70061115e-02, -2.75314214e-02,\n",
       "        -3.29077153e-02, -1.98715173e-01,  3.89839429e-01,\n",
       "         1.41226899e-01, -1.20821148e-01,  8.89381984e-03,\n",
       "         4.35522595e-02,  1.26891370e-02,  4.56402959e-01,\n",
       "        -1.08054306e-02,  4.79100771e-02, -1.19492667e-01,\n",
       "        -4.11636761e-02, -2.70000994e-01, -5.49544342e-03,\n",
       "         2.47272029e-01,  7.76062653e-02, -1.27292888e-01,\n",
       "         1.54417293e-01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_train_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes 0.808\n",
      "KNN 0.9019999999999999\n",
      "Random Forest 0.8699999999999999\n",
      "Logistic Regression 0.8220000000000001\n",
      "SVM 0.808\n",
      "Decision Tree 0.8029999999999999\n",
      "XGBoost 0.8710000000000001\n"
     ]
    }
   ],
   "source": [
    "## Normalized\n",
    "## Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "print('Naive Bayes', cross_val_score(nb_model,norm_train_data,train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "## KNN\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 5)\n",
    "print('KNN', cross_val_score(knn_model, norm_train_data, train_labels.values.ravel(),cv=10).mean())\n",
    "\n",
    "## random forest\n",
    "rfc_model = RandomForestClassifier(n_estimators = 100, random_state = 99)\n",
    "print('Random Forest',cross_val_score(rfc_model, norm_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "## logistic regression\n",
    "lr_model = LogisticRegression(solver = 'saga')\n",
    "print('Logistic Regression', cross_val_score(lr_model, norm_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "svc_model = SVC(gamma = 'auto')\n",
    "print('SVM', cross_val_score(svc_model, norm_train_data, train_labels.values.ravel(),cv=10).mean())\n",
    "\n",
    "dtree_model = DecisionTreeClassifier()\n",
    "print('Decision Tree', cross_val_score(dtree_model,norm_train_data,train_labels.values.ravel(),cv=10).mean())\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "print('XGBoost', cross_val_score(xgb,norm_train_data, train_labels.values.ravel(),cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25054403 0.2055048  0.08026473 0.05033658 0.0489595  0.04489904\n",
      " 0.0417078  0.0312793  0.0230981  0.02100041 0.01617511 0.01263041]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=12)\n",
    "pca_train_data = pca.fit_transform(train_data)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 12)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes 0.8379999999999999\n",
      "KNN 0.9099999999999999\n",
      "Random Forest 0.905\n",
      "Logistic Regression 0.8240000000000001\n",
      "SVM 0.9049999999999999\n",
      "Decision Tree 0.793\n",
      "XGBoost 0.875\n"
     ]
    }
   ],
   "source": [
    "## Normalized\n",
    "## Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "print('Naive Bayes', cross_val_score(nb_model,pca_train_data,train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "## KNN\n",
    "knn_model = KNeighborsClassifier(n_neighbors = 5)\n",
    "print('KNN', cross_val_score(knn_model, pca_train_data, train_labels.values.ravel(),cv=10).mean())\n",
    "\n",
    "## random forest\n",
    "rfc_model = RandomForestClassifier(n_estimators = 100, random_state = 99)\n",
    "print('Random Forest',cross_val_score(rfc_model, pca_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "## logistic regression\n",
    "lr_model = LogisticRegression(solver = 'saga')\n",
    "print('Logistic Regression', cross_val_score(lr_model, pca_train_data, train_labels.values.ravel(), cv=10).mean())\n",
    "\n",
    "svc_model = SVC(gamma = 'auto')\n",
    "print('SVM', cross_val_score(svc_model, pca_train_data, train_labels.values.ravel(),cv=10).mean())\n",
    "\n",
    "dtree_model = DecisionTreeClassifier()\n",
    "print('Decision Tree', cross_val_score(dtree_model, pca_train_data,train_labels.values.ravel(),cv=10).mean())\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "print('XGBoost', cross_val_score(xgb, pca_train_data, train_labels.values.ravel(),cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_all shape : (10000, 40)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "x_all = np.r_[train_data, test_data] ## function to join two data set\n",
    "print('x_all shape :', x_all.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.29940251, -1.22662419,  1.49842505, ..., -2.71555881,\n",
       "        -2.68240859,  0.10105047],\n",
       "       [-1.17417585,  0.33215734,  0.94991875, ...,  1.21321926,\n",
       "         1.38293163, -1.81776106],\n",
       "       [ 1.19222208, -0.41437073,  0.06705418, ...,  0.6564375 ,\n",
       "        -0.93247282,  2.9874358 ],\n",
       "       ...,\n",
       "       [ 0.05227421, -1.73655765, -0.26369872, ...,  1.1796059 ,\n",
       "         1.15633997, -1.21856135],\n",
       "       [ 1.44365875,  0.65189194,  0.55072377, ..., -0.42495429,\n",
       "         1.33337425,  2.32527112],\n",
       "       [-0.42914491, -0.11082132,  1.2572304 , ...,  0.61748452,\n",
       "         1.46443756,  3.30144546]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Best Score 0.996\n",
      "Random Forest Best Params {'max_depth': 3, 'n_estimators': 10}\n",
      "Random Forest Best Accuracy 0.9960000000000001\n",
      "KNN Best Score 0.996\n",
      "KNN Best Params {'n_neighbors': 3}\n",
      "KNN Best Accuracy 0.9960000000000001\n",
      "SVM Best Score 0.996\n",
      "SVM Best Params {'C': 1, 'kernel': 'linear'}\n",
      "SVM Best Accuracy 0.9960000000000001\n"
     ]
    }
   ],
   "source": [
    "## Gaussian Mixture Model\n",
    "lowest_bic = np.infty\n",
    "bic = []\n",
    "n_components_range = range(1,7)\n",
    "cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "for cv_type in cv_types:\n",
    "    for n_components in n_components_range:\n",
    "        gmm = GaussianMixture(n_components=n_components, covariance_type=cv_type)\n",
    "        gmm.fit(x_all)\n",
    "        bic.append(gmm.aic(x_all))\n",
    "        if bic[-1] < lowest_bic:\n",
    "            lowest_bic = bic[-1]\n",
    "            best_gmm = gmm\n",
    "\n",
    "best_gmm.fit(x_all)\n",
    "gmm_train = best_gmm.predict_proba(train_data)\n",
    "gmm_test  = best_gmm.predict_proba(test_data)\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=99)\n",
    "\n",
    "n_estimators = [10, 50, 100, 200, 400]\n",
    "max_depth = [3, 10, 20, 40]\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "grid_search_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=10, scoring='accuracy', n_jobs=-1).fit(gmm_train, train_labels.values.ravel())\n",
    "rfc_best = grid_search_rfc.best_estimator_\n",
    "print('Random Forest Best Score', grid_search_rfc.best_score_)\n",
    "print('Random Forest Best Params', grid_search_rfc.best_params_)\n",
    "print('Random Forest Best Accuracy', cross_val_score(rfc_best, gmm_train, train_labels.values.ravel(),cv=10).mean())\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "n_neighbors = [3,5,6,7,8,9,10]\n",
    "param_grid = dict(n_neighbors=n_neighbors)\n",
    "\n",
    "grid_search_knn = GridSearchCV(estimator=knn, param_grid=param_grid, cv=10, scoring='accuracy', n_jobs=-1).fit(gmm_train, train_labels.values.ravel())\n",
    "knn_best = grid_search_knn.best_estimator_\n",
    "print('KNN Best Score', grid_search_knn.best_score_)\n",
    "print('KNN Best Params', grid_search_knn.best_params_)\n",
    "print('KNN Best Accuracy', cross_val_score(knn_best, gmm_train, train_labels.values.ravel(),cv=10).mean())\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "parameters = [{'kernel':['linear'], 'C':[1,10,100]},\n",
    "             {'kernel':['rbf'], 'C':[1,10,100],'gamma':[0.05,0.0001,0.01,0.001]}]\n",
    "\n",
    "grid_search_svm = GridSearchCV(estimator=svc, param_grid=parameters, cv=10, n_jobs=-1,scoring='accuracy').fit(gmm_train,train_labels.values.ravel())\n",
    "svm_best = grid_search_svm.best_estimator_\n",
    "print('SVM Best Score', grid_search_svm.best_score_)\n",
    "print('SVM Best Params', grid_search_svm.best_params_)\n",
    "print('SVM Best Accuracy', cross_val_score(svm_best, gmm_train, train_labels.values.ravel(),cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_best.fit(gmm_train, train_labels.values.ravel())\n",
    "pred = rfc_best.predict(gmm_test)\n",
    "rfc_best_pred = pd.DataFrame(pred)\n",
    "\n",
    "rfc_best_pred.index += 1\n",
    "\n",
    "rfc_best_pred.columns = ['Solution']\n",
    "rfc_best_pred['Id'] = np.arange(1,rfc_best_pred.shape[0]+1)\n",
    "rfc_best_pred = rfc_best_pred[['Id', 'Solution']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Solution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>8996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>8997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>8998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>8999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000</th>\n",
       "      <td>9000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Solution\n",
       "1        1         1\n",
       "2        2         0\n",
       "3        3         1\n",
       "4        4         0\n",
       "5        5         0\n",
       "...    ...       ...\n",
       "8996  8996         0\n",
       "8997  8997         1\n",
       "8998  8998         1\n",
       "8999  8999         0\n",
       "9000  9000         1\n",
       "\n",
       "[9000 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_best_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_best_pred.to_csv('Submission_GMM_RFC.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
